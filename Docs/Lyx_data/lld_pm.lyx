#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\date{}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip smallskip
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Low Level Design Document
\begin_inset Newline newline
\end_inset

Predictive maintenance
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Document Control
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Date issued
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Version
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Description
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\series bold
Authors
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
02-05-22
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Initial LLD
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Shikhar Amar, Hitesh Pathak
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
What is Low level design document ?
\end_layout

\begin_layout Standard
The purpose of a low-level design document (LLDD) is to provide the internal
 logical structure of the program, which in this case is the RUL detection
 system for Predictive maintenance of turbofan jet engines.
 It describes the core components of the program identified during High-level
 design phase, and the logical relation between them, so that the developers
 can program the solution and maintain / debug with ease.
\end_layout

\begin_layout Subsection
Scope
\end_layout

\begin_layout Standard
LLD is a design process for components of the system identified in the HLD
 phase.
 The process details the architecture and implementation details of all
 these components and continuously refines the design over the course of
 development.
 These components can include data-structures, required software architecture,
 source code and performance optimization code.
 The data organization is defined during requirement analysis of project,
 and refined during data-design phase.
 After the architecture is build each component is described in detail.
\end_layout

\begin_layout Subsection
Definitions
\end_layout

\begin_layout Standard
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="2">
<features booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top" width="0pt">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Terms
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Meaning
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
LLD
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Low-level design
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
RUL
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Remaining useful life
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
API
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Application programming interface
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
DB
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Database
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CSV file
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Comma separated values file
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Architecture
\end_layout

\begin_layout Standard
The flow-chart describing the architecture and data-flow through the architectur
al components is shown below :
\end_layout

\begin_layout Standard
\begin_inset Graphics
	filename graphics/architecture_better.png
	scale 67

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Architecture description
\end_layout

\begin_layout Subsection
Training data description
\begin_inset CommandInset label
LatexCommand label
name "subsec:Data-description"

\end_inset


\end_layout

\begin_layout Standard
The training data consists of several data sets, each consisting of multiple
 multivariate time series, where a unit of time is a cycle of operation
 of the engine.
 Each time series in the set corresponds to a different engine, hence the
 data can be considered to be from a fleet of similar engines.
 Each engine starts with a different initial condition including manufacturing
 flaws, variations.
 As the time series progresses, the engine develops a fault which leads
 to its breakdown.
\end_layout

\begin_layout Standard
The data sets include three operational settings and data from 21 sensors,
 all columns in the data set indicate different variables as shown :
\end_layout

\begin_layout Enumerate
Unit number of engine.
\end_layout

\begin_layout Enumerate
Time in cycles of operation.
\end_layout

\begin_layout Enumerate
Operational setting 1
\end_layout

\begin_layout Enumerate
Operational setting 2
\end_layout

\begin_layout Enumerate
Operational setting 3
\end_layout

\begin_layout Enumerate
Sensor 1
\end_layout

\begin_layout Enumerate
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
setcounter{enumi}{25}
\end_layout

\end_inset

Sensor 2
\end_layout

\begin_deeper
\begin_layout Standard
\SpecialChar ldots

\end_layout

\end_deeper
\begin_layout Enumerate
Sensor 21
\end_layout

\begin_layout Subsection
Model Training process flow :
\end_layout

\begin_layout Subsubsection
Data validation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Data-validation"

\end_inset


\end_layout

\begin_layout Standard
Along with the data sets described in
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Data-description"
plural "false"
caps "false"
noprefix "false"

\end_inset

 a 
\emph on
schema
\emph default
 file is also required, which is used for data validation.
 Schema is a .json file that contains all the necessary metadata about the
 training data sets - file names, column names, number of columns, datatype
 of columns.
 This file is checked against the training data for its validation.
 The process follows the following steps :
\end_layout

\begin_layout Description
Name
\begin_inset space ~
\end_inset

validation The schema file contains the specifications for file name, a
 regex pattern is created according to this specification and the filename
 of training data sets is matched against the pattern, If a match is found,
 the corresponding data set is moved to 
\emph on
Good_data_folder 
\emph default
otherwise it is moved to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Description
Column
\begin_inset space ~
\end_inset

name Similarly, the name of the columns in the data sets should match with
 the specification present in the schema files.
 Accordingly the file is put into 
\emph on
Good_data_folder 
\emph default
or 
\emph on
Bad_data_folder.
\end_layout

\begin_layout Description
Number
\begin_inset space ~
\end_inset

of
\begin_inset space ~
\end_inset

columns The schema specifies the permissible number of columns present in
 the data set, the files that validate against schema are moved to 
\emph on
Good_data_folder 
\emph default
and otherwise to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Description
Column
\begin_inset space ~
\end_inset

datatype The datatype of each column should be the same as that specified
 in the schema file, following which the data is put in 
\emph on
Good_data_folder 
\emph default
and failing which it is put in 
\emph on
Bad_data_folder.
\end_layout

\begin_layout Subsubsection
Insertion of data sets into database
\begin_inset CommandInset label
LatexCommand label
name "subsec:Insertion-of-data"

\end_inset


\end_layout

\begin_layout Standard
After the training data is validated, it has to be stored in a database.
 This is achieved following the steps listed below :
\end_layout

\begin_layout Description
Connect
\begin_inset space ~
\end_inset

to
\begin_inset space ~
\end_inset

DB
\begin_inset space ~
\end_inset

system Establish connect to the database system which might be a server
 running locally or a cloud DB system, depending upon the developers.
 In our implementation we will be using 
\emph on
DataStax Astra DB
\emph default
 system which uses Apache Cassandra database.
\end_layout

\begin_layout Description
Create
\begin_inset space ~
\end_inset

database
\begin_inset space ~
\end_inset

and
\begin_inset space ~
\end_inset

connect A database is created on Astra DB and a connection is established
 to the database.
\end_layout

\begin_layout Description
Create
\begin_inset space ~
\end_inset

data
\begin_inset space ~
\end_inset

table In the database, multiple tables are created, the schema of the tables
 i.e., field names, data types are inferred from the 
\emph on
schema
\emph default
 file.
 If old tables are already present containing previously imported training
 data, they are not replaced or modified, instead new table are created.
 So that the models can learn from old as well as new data.
\end_layout

\begin_layout Description
Data
\begin_inset space ~
\end_inset

insertion The validated training data files are present in 
\emph on
Good_data_folder
\emph default
, the data from these files is uploaded to the appropriate tables.
 Since different data sets correspond to different type of training data,
 multiple columns are mandatory and the data sets should 
\emph on
not
\emph default
 be combined together.
 If importing a file leads to an error because of the file type (column
 mismatch, datatype mismatch etc.) the same file is moved to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Subsubsection
Model training
\end_layout

\begin_layout Standard
After the validated data is inserted into the database, it can be used to
 train models.
 This process is elaborated below :
\end_layout

\begin_layout Description
Exporting
\begin_inset space ~
\end_inset

data
\begin_inset space ~
\end_inset

from\SpecialChar softhyphen
DB The training data sets are present as tables in the database.
 These tables are exported to a .csv (comma separated values) file, that
 is used for training.
\end_layout

\begin_layout Description
Data
\begin_inset space ~
\end_inset

pre-processing In this step, the csv files are loaded into pandas 
\emph on
DataFrame 
\emph default
objects, and the data is cleaned and modified.
 This involves following sub steps :
\end_layout

\begin_deeper
\begin_layout Itemize
All sensor data columns are checked for standard deviation, if any of them
 has zero standard deviation, it's deleted from the data set as it does
 not provide any useful information.
\end_layout

\begin_layout Itemize
If any sensor data columns contain 
\emph on
NULL 
\emph default
or missing entries, these are imputed using KNN (k nearest neighbors) Imputer.
\end_layout

\end_deeper
\begin_layout Description
Data
\begin_inset space ~
\end_inset

Clustering Pre-processed data is fed into K-means algorithm to create clusters,
 the reason behind clustering is to implement different algorithms for the
 clusters.
 K-means model is trained over pre-processed data and the model is saved
 for later predictions.
 The 
\emph on
Elbow plot
\emph default
 of the data is used to find the optimal number of clusters, this is achieved
 dynamically using 
\emph on
Knee-locator 
\emph default
function.
\end_layout

\begin_layout Description
Model
\begin_inset space ~
\end_inset

selection In this step, we find the best model for each cluster of data.
 Two algorithms are being used in this implementation - 
\emph on
Random Forest 
\emph default
and 
\emph on
XGBoost
\emph default
.
 For each algorithm the parameters are calculated using GridSearch, thereafter
 the 
\emph on
AUC 
\emph default
scores are evaluated for each of the models and the one with the best score
 is selected.
 All models selected using this procedure are saved for predictions.
\end_layout

\begin_layout Subsection
Test data description
\end_layout

\begin_layout Standard
The test data sets are similar to training data sets.
 They also include multiple data sets with time series data of a fleet of
 engines that undergo degradation.
 The column names and the operational settings are exactly the same, the
 only difference for test data sets is that the time series of each engine
 stops sometime before breakdown, unlike the training data sets wherein
 the data is Run-to-failure.
\end_layout

\begin_layout Standard
The end goal of RUL prediction system is the predict the remaining useful
 life for the engines in test data set, this is equivalent to the number
 of remaining cycles that the engine can undergo after the last operational
 cycle in its test series and before it breaks down.
\end_layout

\begin_layout Subsection
Prediction process flow
\end_layout

\begin_layout Subsubsection
Data validation
\end_layout

\begin_layout Standard
Along with the test data, a schema file is required.
 Schema lists the relevant metadata about data-sets - file names, column
 names, number of columns, datatype of columns.
 The validation process is exactly similar to that in the training case
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Data-validation"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Description
Name
\begin_inset space ~
\end_inset

validation The schema file contains the specifications for file name, a
 regex pattern is created according to this specification and the filename
 of training data sets is matched against the pattern, If a match is found,
 the corresponding data set is moved to 
\emph on
Good_data_folder 
\emph default
otherwise it is moved to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Description
Column
\begin_inset space ~
\end_inset

name Similarly, the name of the columns in the data sets should match with
 the specification present in the schema files.
 Accordingly the file is put into 
\emph on
Good_data_folder 
\emph default
or 
\emph on
Bad_data_folder.
\end_layout

\begin_layout Description
Number
\begin_inset space ~
\end_inset

of
\begin_inset space ~
\end_inset

columns The schema specifies the permissible number of columns present in
 the data set, the files that validate against schema are moved to 
\emph on
Good_data_folder 
\emph default
and otherwise to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Description
Column
\begin_inset space ~
\end_inset

datatype The datatype of each column should be the same as that specified
 in the schema file, following which the data is put in 
\emph on
Good_data_folder 
\emph default
and failing which it is put in 
\emph on
Bad_data_folder.
\end_layout

\begin_layout Subsubsection
Insertion of data into database
\end_layout

\begin_layout Standard
This step is also exactly similar to
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Insertion-of-data"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Description
Connect
\begin_inset space ~
\end_inset

to
\begin_inset space ~
\end_inset

DB
\begin_inset space ~
\end_inset

system Establish connect to the database system which might be a server
 running locally or a cloud DB system, depending upon the developers.
 In our implementation we will be using 
\emph on
DataStax Astra DB
\emph default
 system which uses Apache Cassandra database.
\end_layout

\begin_layout Description
Create
\begin_inset space ~
\end_inset

database
\begin_inset space ~
\end_inset

and
\begin_inset space ~
\end_inset

connect A database is created on Astra DB and a connection is established
 to the database.
\end_layout

\begin_layout Description
Create
\begin_inset space ~
\end_inset

data
\begin_inset space ~
\end_inset

table In the database, multiple tables are created, the schema of the tables
 i.e., field names, data types are inferred from the 
\emph on
schema
\emph default
 file.
 If old tables are already present containing previously imported training
 data, they are not replaced or modified, instead new table are created.
 So that the models can learn from old as well as new data.
\end_layout

\begin_layout Description
Data
\begin_inset space ~
\end_inset

insertion The validated training data files are present in 
\emph on
Good_data_folder
\emph default
, the data from these files is uploaded to the appropriate tables.
 Since different data sets correspond to different type of training data,
 multiple columns are mandatory and the data sets should 
\emph on
not
\emph default
 be combined together.
 If importing a file leads to an error because of the file type (column
 mismatch, datatype mismatch etc.) the same file is moved to 
\emph on
Bad_data_folder
\emph default
.
\end_layout

\begin_layout Subsubsection
Prediction of RUL
\end_layout

\begin_layout Standard
After the validated data is inserted into the database, the trained ML algorithm
s are used to model it and predict RUL for the engines.
 The steps involved are explained below :
\end_layout

\begin_layout Description
Exporting
\begin_inset space ~
\end_inset

data
\begin_inset space ~
\end_inset

from\SpecialChar softhyphen
DB The training data sets are present as tables in the database.
 These tables are exported to a .csv (comma separated values) file.
\end_layout

\begin_layout Description
Data
\begin_inset space ~
\end_inset

pre-processing In this step, the csv files are loaded into pandas 
\emph on
DataFrame 
\emph default
objects, and the data is cleaned and modified.
 This involves following sub steps :
\end_layout

\begin_deeper
\begin_layout Itemize
All sensor data columns are checked for standard deviation, if any of them
 has zero standard deviation, it's deleted from the data set as it does
 not provide any useful information.
\end_layout

\begin_layout Itemize
If any sensor data columns contain 
\emph on
NULL 
\emph default
or missing entries, these are imputed using KNN (k nearest neighbors) Imputer.
\end_layout

\end_deeper
\begin_layout Description
Data
\begin_inset space ~
\end_inset

Clustering The K-means model trained during the clustering of training data
 is loaded.
 This model is used to predict clusters of the pre-processed test data sets.
\end_layout

\begin_layout Description
RUL
\begin_inset space ~
\end_inset

prediction After data is clustered, each cluster is loaded and based on
 its cluster number, a corresponding ML model is loaded, this model was
 saved during the training phase.
 The model is used to predict remaining useful life RUL for all data points
 in the cluster.
\begin_inset Newline newline
\end_inset

After the predictions are done for all clusters, RUL along with engine number
 are written to a csv file.
 This file is then exported to Astra DB.
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Deployment
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
